# ğŸ“šAll-in-One AI Reference Guide

This webpage offers a curated, category-wise collection of resources in **Artificial Intelligence**â€”including **courses, books, playlists, research papers, blogs, code snippets, and repositories** .

<div align="left">
  <a href="https://www.linkedin.com/in/bhoop-singh-gurjar-%F0%9F%87%AE%F0%9F%87%B3-3b41b41a9/" target="_blank">
    <img src="https://img.shields.io/static/v1?message=LinkedIn&logo=linkedin&label=BhoopSinghGurjar&color=0077B5&logoColor=white&labelColor=&style=for-the-badge" height="25" alt="linkedin logo"  />
  </a>
</div>
 
<div align="left">
  <img src="https://visitor-badge.laobi.icu/badge?page_id=bhoopsinghgurjar.bhoopsinghgurjar&" />
</div>



---
## ğŸš€Quick Links

| Category                           | Category                                | Category                               |
|------------------------------------|-----------------------------------------|----------------------------------------|
| ğŸ§  [LLM Architectures](#llm-architectures)      | ğŸ”¥ [Machine Learning](#machine-learning)   | âœï¸ [GPUs](#gpu)  |
| ğŸ“— [RLHF](#rlhf)                                | ğŸ”— [Chain of Thought](#chain-of-thought)   | ğŸ” [AI Math](#ai-math)                 |
| ğŸ­ [ML](#machine-learning)                      | ğŸ† [Deep Learning](#deep-learning)         |ğŸ§© [NLP](#nlp)                     |
| ğŸ–¼ï¸ [Computer Vision](#computer-vision)          | ğŸ® [Reinforcement Learning](#reinforcement-learning) | ğŸ¨ [CNNs](#-cnns)                 |
| ğŸ” [DPO](#dpo)                                  | ğŸ” [RNNs](#rnns)                           | ğŸ§¾ [Image Classification](#-image-classification) | 
|âš¡ [Model Technical Paper](#model-technical-paper) | â›³[Books](#books)                        | ğŸ‚[LLM Reinforcement Learning](#llm-reinforcement-learning)|
|ğŸƒ[Mixture of expert](#mixture-of-expert)        | ğŸ¦’[Fine-tuning](#fine-tuning)              | ğŸª°[Tensor](#tensor)|
|ğŸ§â€â™€ï¸[Supervised Learning](#supervised-learning)    | ğŸ¦â€ğŸ”¥[IISC Bangalore](#iisc-bangalore)        | ğŸ§œâ€â™‚ï¸[AI Agent](#ai-agent)|
|ğŸ«€[Artificial Intelligence](#artificial-intelligence) |ğŸ§˜â€â™‚ï¸[Prompt Engineering](#prompt-engineering)      |ğŸ•·ï¸[Statistical](#statistical) |
|ğŸ§¬[Generative AI](#generative-ai)                   |ğŸ¡[Stanford University](#stanford-university)    |ğŸ¦[How To Make LLM](#how-to-make-llm)|
|ğŸ[Pytorch](#pytorch)                               |ğŸ£[Karpathy](#karpathy)                          |ğŸ•Šï¸[How To Make LLM](#how-to-make-llm)|
|ğŸª¶[LLM Inference](#llm-inference)                   |ğŸ¦­[LLM-powered phone](#llm-powered-phone)        |ğŸ¦Ÿ[Diffusion Model](#diffusion-model) |
|ğŸª¢[Backpropagation](#backpropagation)               |ğŸ“€[Attention](#attention)                        |ğŸ§šâ€â™‚ï¸[BERT](#bert)                      |
|ğŸ¦´[Few-Shot](#few-shot)                             |ğŸ‘©â€ğŸš€[Scaling Laws](#scaling-laws)             |ğŸ¿ï¸[LoRA](#lora) |
|ğŸ¦‡[RAG](#rag)                 |ğŸº[AI Youtube Channel](#ai-youtube-channel)       |ğŸ«[AI Blog](#ai-blog)       |
|ğŸ˜»[Embedding](#embedding)                           |ğŸ·[Neural Network](#neural-network)               |ğŸ¦„[AGI](#agi) |
|ğŸ˜[AI beat Human](#ai-beat-human)             | ğŸª[Vision Transformer](#vision-transformer)    |ğŸ¦[History](#history)|
|ğŸ¦“ [AI Learning Guide](#ai-learning-guide)    | ğŸ¦–[Roadmap](#roadmap)           |  ğŸˆ[Interview](#interview) |
| ğŸ«[UC Berkeley University](#uc-berkeley-university) |ğŸ²[LLM alignment](#llm-alignment)| ğŸ•[Reward Modeling](#reward-modeling)|
| ğŸ«[LLM preference](#llm-preference)| ğŸ«[LLM Reasoning](#llm-reasoning)| ğŸƒ[Positional Encoding](#positional-encoding)|
|ğŸ¸[Database](#database)| ğŸª¼[Chunking](#chunking)| ğŸ¦¨[Top AI Papers of the Week](#top-ai-papers-of-the-week)|
|ğŸ¦§[Topic Comparison](#topic-comparison)|ğŸ’«[LLM from scratch](#llm-from-scratch)|ğŸ¾[N8N](#n8n)|
|ğŸ[Agents Protocol](#agents-protocol)| ğŸ¤´[Programming Massively Parallel Processors](#programming-massively-parallel-processors)|











---
More coming soon..

## ğŸ†Deep Learning

ğŸ”™ [Back to Categories](#quick-links)

---

### ğŸ“š Deep Learning Books

| #  | ğŸ“˜ Book Name                                                    | ğŸ”— Link |
|----|------------------------------------------------------------------|--------|
| 1  | Deep Learning â€“ Ian Goodfellow                                  | [Link](https://www.deeplearningbook.org/) |
| 2  | Understanding Deep Learning                                     | [Link](https://udlbook.github.io/udlbook/) |
| 3  | Dive into Deep Learning                                         | [Link](https://d2l.ai) |
| 4  | The Little Book of Deep Learning                                | [Link](https://fleuret.org/public/lbdl.pdf) |
| 5  | Grokking Deep Learning                                          | [Link](https://cdn.ttgtmedia.com/rms/pdf/grokking_deep_learning.pdf) |
| 6  | Practical Deep Learning for Coders â€“ fastai                     | [Link](https://course.fast.ai/Resources/book.html) |
| 7  | Meta Learning â€“ How To Learn Deep Learning And Thrive...        | [Link](https://studylib.net/doc/26113326/radek-osmulski---meta-learning--how-to-learn-deep-learnin...) |
| 8  | David MacKay â€“ Information Theory, Inference, and Learning Algorithms | [Link](https://www.inference.org.uk/itprnn/book.pdf) |

---

### ğŸ“ Deep Learning Courses

ğŸ”™ [Back to Categories](#quick-links)

| #  | ğŸ¥ Course Name                                                                 | ğŸ”— Link |
|----|--------------------------------------------------------------------------------|--------|
| 1  | DeepLearning.AI                                                                | [Link](https://www.deeplearning.ai/) |
| 2  | NYU Deep Learning â€“ Yann LeCun                                                 | [Link](https://atcold.github.io/NYU-DLSP21/) |
| 3  | The Complete Mathematics of Neural Networks and Deep Learning                 | [Link](https://www.youtube.com/watch?v=Ixl3nykKG9M) |
| 4  | Intro to Deep Learning â€“ Sebastian Raschka                                     | [Link](https://www.youtube.com/playlist?list=PLTKMiZHVd_2KJtIXOW0zFhFfBaJJilH51) |
| 5  | Practical Deep Learning for Coders â€“ fastai                                    | [Link](https://course.fast.ai/) |
| 6  | Full Stack Deep Learning â€“ 2022                                                | [Link](https://fullstackdeeplearning.com/course/2022/) |
| 7  | David MacKay â€“ Information Theory, Pattern Recognition, and Neural Networks    | [Link](https://www.youtube.com/playlist?list=PLruBu5BI5n4aFpG32iMbdWoRVAA-Vcso6) |
| 8  | UC Berkeley CS 182: Deep Learning                                               | [Link](https://www.youtube.com/playlist?list=PL_iWQOsE6TfVmKkQHucjPAoRtIJYt8a5A) |
| 9  | MIT â€“ Introduction to Deep Learning                                            | [Link](https://introtodeeplearning.com/) |
| 10 | CS231n â€“ Deep Learning for Computer Vision                                     | [Link](https://cs231n.stanford.edu/) |
| 11 | CS224d â€“ Deep Learning for Natural Language Processing                         | [Link](https://www.youtube.com/playlist?list=PL4PDl8a0S5tvphRVF45G8B7z0pDO6MT7C) |
| 12 | Machine Learning - Caltech by Yaser Abu-Mostafa (2012-2014) | [Link](https://lnkd.in/gFrJZMyc)|
| 13 | Neural networks class by Hugo Larochelle from UniversitÃ© de Sherbrooke (2013) | [Link](https://lnkd.in/gp_yWima)|
|14 | A.I - MIT by Patrick Henry Winston (2010) |[Link](https://lnkd.in/gxaai466)|
|15 | Vision and learning - computers and brains by Shimon Ullman, Tomaso Poggio, Ethan Meyers @ MIT (2013) |[Link](https://lnkd.in/gndivz6G)|
|16 | Deep Learning for Natural Language Processing - Stanford(2017) |[Link](https://lnkd.in/g7qN9W9N)|
| 17 | Machine Learning - Oxford (2014-2015) |[Link](https://lnkd.in/gAim2CuT)|
| 18 | Deep Learning - UWaterloo by Prof. Ali Ghodsi at University of Waterloo (2015) |[Link](https://lnkd.in/gAqHveGS)|
| 19 | Statistical Machine Learning - CMU by Prof. Larry Wasserman |[Link](https://lnkd.in/gAM829ec)|
| 20 |  Introduction to Deep Learning by Prof. Bhiksha Raj (2017) |[Link](https://lnkd.in/ghr3mk9J)|
| 21 | Deep Learning - UC Berkeley STAT-157 by Alex Smola and Mu Li (2019) |[Link](https://lnkd.in/gyMccbeB) |





---

## ğŸ¨ CNNs
---

ğŸ”™ [Back to Categories](#quick-links)

| #  | ğŸ“„ Title                                                                 | ğŸ”— Link |
|----|--------------------------------------------------------------------------|--------|
| 1  | CNN from Scratch with pure Mathematical Intuition                        | [Link](https://lunar-joke-35b.notion.site/CNN-from-Scratch-with-pure-Mathematical-Intuition-a201ef0ca1314058a1707a3ae260981e) |
| 2  | Convolutional Neural Network (CNN): A Complete Guide                     | [Link](https://learnopencv.com/understanding-convolutional-neural-networks-cnn/) |
| 3  | CNN Explainer                                                            | [Link](https://poloclub.github.io/cnn-explainer/) |
| 4  | ConvNetJS â€“ Deep Learning in your browser                                | [Link](https://cs.stanford.edu/people/karpathy/convnetjs/index.html) |
| 5  | Convolutional Neural Networks Explained (CNN Visualized)                 | [Link](https://www.youtube.com/watch?v=pj9-rr1wDhM) |
| 6  | CNNs from different viewpoints                                           | [Link](https://cs231n.github.io/understanding-cnn/) |
| 7  | Image Kernels                                                            | [Link](https://setosa.io/ev/image-kernels/) |
| 8  | Visualizing what ConvNets learn                                          | [Link](https://www.youtube.com/watch?v=8rrHTtUzyZA) |
| 9  | Convolutions in Image Processing                                         | [Link](https://www.youtube.com/watch?v=8rrHTtUzyZA) |
| 10 | Understanding â€œconvolutionâ€ operations in CNN                            | [Link](https://medium.com/analytics-vidhya/convolution-operations-in-cnn-deep-learning-compter-vision-128906ece7d3) |
| 11 | Convolutional Neural Networks, Explained                                 | [Link](https://towardsdatascience.com/convolutional-neural-networks-explained-9cc5188c4939/) |


---

## ğŸ”¥Pytorch
ğŸ”™ [Back to Categories](#quick-links)

| #  | ğŸ“„ Title                                                                 | ğŸ”— Link |
|----|--------------------------------------------------------------------------|--------|
| 1  | Zero to Mastery Learn PyTorch for Deep Learning          | [Link](https://www.learnpytorch.io/) |
| 2  | Learn PyTorch for deep learning in a day. Literally.      | [Link](https://www.youtube.com/watch?v=Z_ikDlimN6A) |
| 3  | PyTorch internals - ezyangâ€™s blog                                        | [Link](https://blog.ezyang.com/2019/05/pytorch-internals/) |
| 4  | MiniTorch                                                                | [Link](https://minitorch.github.io/) |
| 5  | PyTorch is dead. Long live JAX. - Blog                                   | [Link](https://neel04.github.io/my-website/blog/pytorch_rant/) |
| 6  | Inside the Matrix: Visualizing Matrix Multiplication, Attention and Beyond | [Link](https://pytorch.org/blog/inside-the-matrix/) |




## Programming Massively Parallel Processors
ğŸ”™ [Back to Categories](#quick-links)

| #  | ğŸ“„ Title                                                                 | ğŸ”— Link |
|----|--------------------------------------------------------------------------|--------|
| 1  | Programming Massively Parallel Processors(2021)         | [Link](https://www.youtube.com/playlist?list=PLRRuQYjFhpmubuwx-w8X964ofVkW1T8O4) |
| 2  | Programming Massively Parallel Processors(2019)         |[Link](https://www.youtube.com/watch?v=WJ0BAlaXFUc&list=PLRRuQYjFhpmspsME4LmLbuCG1VHbJmIcy)|
|3   |Programming Massively Parallel Processors Book           |[Link](https://www.cse.iitd.ac.in/~rijurekha/col730_2022/cudabook.pdf)|
| 4  | CUDA C++ Programming Guide                              |[Link](https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html)|
| 5  | How GPU Computing Works | GTC 2021                      |[Link](https://www.youtube.com/watch?v=3l10o0DYJXg)|
| 6  |GPU Programming: When, Why and How?                      |[Link](https://enccs.github.io/gpu-programming/)|
| 7  | Making Deep Learning Go Brrrr From First Principles      |[Link](https://horace.io/brrr_intro.html)|






## ğŸ§ RNNs
ğŸ”™ [Back to Categories](#quick-links)

| #  | ğŸ“„ Title                                                                 | ğŸ”— Link |
|----|--------------------------------------------------------------------------|--------|
| 1  | Recurrent Neural Networks Tutorial, Part 1 â€“ Introduction to RNNs        | [Link](https://dennybritz.com/posts/wildml/recurrent-neural-networks-tutorial-part-1/) |
| 2  | Understanding LSTM Networks                                              | [Link](https://colah.github.io/posts/2015-08-Understanding-LSTMs/) |
| 3  | Predict Stock Prices Using RNN: Part 1                                   | [Link](https://lilianweng.github.io/posts/2017-07-08-stock-rnn-part-1/) |
| 4  | Recurrent Neural Networks (RNN) - Made With ML                           | [Link](https://madewithml.com/courses/foundations/recurrent-neural-networks/) |
| 5  | RNNs and LSTMs - jurafsky, stanford                                      | [Link](https://web.stanford.edu/~jurafsky/slp3/8.pdf) |
| 6  | The Unreasonable Effectiveness of Recurrent Neural Networks - Karpathy   | [Link](https://karpathy.github.io/2015/05/21/rnn-effectiveness/) |
| 7  | NLP from Scratch - PyTorch                                               | [Link](https://pytorch.org/tutorials/intermediate/nlp_from_scratch_index.html) |




## ğŸ“šLLM Architectures
ğŸ”™ [Back to Categories](#quick-links)

| #  | ğŸ“„ Title                                                                 | ğŸ”— Link |
|----|--------------------------------------------------------------------------|--------|
| 1  |Attention is all you need (Transformer) Umar Jamil                                                               | [Link](https://youtu.be/bCz4OMemCcA?si=bQVwRBoGfbq3QmSr) |
| 2  | Build a Large Language Model (From Scratch) - Sebastian Raschka          | [Link](https://livebook.manning.com/book/build-a-large-language-model-from-scratch/title/) |
| 3  | Create a Large Language Model from Scratch with Python - Tutorial  | [Link](https://youtu.be/UU1WVnMk4E8?si=yx8SsYJz6WIC55BJ) |
| 4  | Intro to Transformers (slides) - giffmana                                | [Link](https://docs.google.com/presentation/d/1ZXFIhYczos679r70Yu8vV9uO6B1J0ztzeDxbnBxD1S0/edit#slide=id.ge2832e38b9_0_21) |
| 5  | [ML 2024] Transformers - Lucas Beyer (giffmana)                          | [Link](https://youtu.be/bMXqnLiVgLk?si=lCrYaB8kATHcS2qb) |
| 6  | TRANSFORMER EXPLAINER - Polo Club                                        | [Link](https://poloclub.github.io/transformer-explainer/) |
| 7  | The Illustrated GPT-2 (Visualizing Transformer Language Models)          | [Link](https://jalammar.github.io/illustrated-gpt2/) |
| 8  | ATTENTION IS ALL YOU NEED - Implementation                               | [Link](https://github.com/LvanderGoten/AttentionIsAllYouNeed?tab=readme-ov-file) |
| 9  | Linear Relationships in the Transformerâ€™s Positional Encoding            | [Link](https://blog.timodenk.com/linear-relationships-in-the-transformers-positional-encoding/) |
| 10 | Implement and Train ViT From Scratch for Image Recognition - PyTorch     | [Link](https://youtu.be/Vonyoz6Yt9c?si=BbpSoWQIujXtyUjW) |
| 11 | a smol course - huggingface                                              | [Link](https://github.com/huggingface/smol-course) |
| 12 | HOW I Studied LLMs in Two Weeks: A Comprehensive Roadmap                | [Link](https://towardsdatascience.com/how-i-studied-llms-in-two-weeks-a-comprehensive-roadmap-e8ac19667a31/) |
| 13 | HOW LARGE LANGUAGE MODELS work - From zero to ChatGPT                    | [Link](https://medium.com/data-science-at-microsoft/how-large-language-models-work-91c362f5b78f) |
| 14 | Building effective agents - Anthropic                                    | [Link](https://www.anthropic.com/engineering/building-effective-agents) |
| 15 | LLM VISUALIZATION                                                        | [Link](https://bbycroft.net/llm) |
| 16 | LLM course - huggingface                                                 | [Link](https://huggingface.co/learn/llm-course/chapter1/1) |
| 17 | Neural Networks: Zero to Hero                                            | [Link](https://www.youtube.com/playlist?list=PLAqhIrjkxbuWI23v9cThsA9GvCAUhRvKZ) |
|18 | Stanford CS229 (2023) | [Link](https://www.youtube.com/watch?v=9vM4p9NN0Ts&ab_channel=StanfordOnline) |
|19 | Building an LLM from Scratch (Sebastian Raschka, 2024) | [Link](https://youtu.be/quh7z1q7-uc)|
| 20 | General Audience Large Language Models (Andrej Karpathy, 2024) |[Link](https://youtu.be/zjkBMFhNj_g)|
| 21 | Foundations of Large Language Models" by Tong Xiao and Jingbo Zhu |[Link](https://readwise-assets.s3.amazonaws.com/media/wisereads/articles/foundations-of-large-language-/2501.09223v1.pdf)|
| 22 | Hands-On Large Language Models |[Link](https://github.com/HandsOnLLM/Hands-On-Large-Language-Models)|
| 23  | The Illustrated Transformer |[Link](https://jalammar.github.io/illustrated-transformer/)|




## Karpathy
ğŸ”™ [Back to Categories](#quick-links)

| #  | ğŸ“„ Title                                                                 | ğŸ”— Link |
|----|--------------------------------------------------------------------------|--------|
| 1  |   Blog       | [Link](https://karpathy.github.io/) |
|2   |Neural Networks: Zero to Hero      | [Link](https://youtube.com/playlist?list=PLAqhIrjkxbuWI23v9cThsA9GvCAUhRvKZ&si=Wy41HIVOqmGAhad_)|
|3  |CS231n Winter 2016 |[Link](https://youtube.com/playlist?list=PLkt2uSq6rBVctENoVBg1TpCC7OQi31AlC&si=N-FLNkPVE9ddnxX5)|
|4 |CS231n: Convolutional Neural Networks for Visual Recognition |[Link](https://cs231n.stanford.edu/2016/)|
|5 | EurekaLabsAI |[Link](https://github.com/EurekaLabsAI)|
|6 | Github |[Link](https://github.com/karpathy) |





## How To Make LLM

ğŸ”™ [Back to Categories](#quick-links)

| #  | ğŸ“„ Title                                                                 | ğŸ”— Link |
|----|--------------------------------------------------------------------------|--------|
| 1  |   How to Scale Your Model by google      | [Link](https://jax-ml.github.io/scaling-book/) |
|2   | The Ultra-Scale Playbook: Training LLMs on GPU Clusters by Huggingface |[Link](https://huggingface.co/spaces/nanotron/ultrascale-playbook)|
| 3  | Tiny LLM - LLM Serving in a Week      |[Link](https://skyzh.github.io/tiny-llm/preface.html) |


## LLM from scratch

ğŸ”™ [Back to Categories](#quick-links)

| #  | ğŸ“„ Title                                                                 | ğŸ”— Link |
|----|--------------------------------------------------------------------------|--------|
| 1  |  Llama from scratch      | [Link](https://blog.briankitano.com/llama-from-scratch/) |


## Agents Protocol

ğŸ”™ [Back to Categories](#quick-links)

| #  | ğŸ“„ Title                                                                 | ğŸ”— Link |
|----|--------------------------------------------------------------------------|--------|
| 1  |Model Context Protocol (MCP) Course by HuggingFace    |[Link](https://huggingface.co/learn/mcp-course/unit0/introduction) |




## Machine Learning

ğŸ”™ [Back to Categories](#quick-links)

| #  | ğŸ“„ Title                                                                 | ğŸ”— Link |
|----|--------------------------------------------------------------------------|--------|
| 1  | Machine Learning Specialization (Coursera) |[Link](https://www.coursera.org/specializations/machine-learning-introduction) |
| 2  | A Visual Introduction to Machine Learning |[Link](http://www.r2d3.us/)|
| 3  | Visual explanations of core machine learning concepts | [Link](https://mlu-explain.github.io/)|
| 4  |Papers & tech blogs by companies sharing their work on data science & machine learning in production. |[Link](https://github.com/eugeneyan/applied-ml)|
| 5  | CS229: Machine Learning |[Link](https://cs229.stanford.edu/)|
| 6  |Pen and Paper Exercises in Machine Learning |[Link](https://arxiv.org/abs/2206.13446)|
|  7 | Interpretable Machine Learning |[Link](https://christophm.github.io/interpretable-ml-book/)|
| 8 | math for data science and machine learning  | [Link](https://www.cis.upenn.edu/~jean/math-deep.pdf)|
|9 | Machine Learning: Probabilistic Perspective |[Link](https://drive.google.com/file/d/12RZS57QKL-jNdGajdmnmvuDnHrcFk76R/view)|
| 10 | XGBOOSTING |[Link](https://xgboosting.com/)|




## Machine Learning related blog  
ğŸ”™ [Back to Categories](#quick-links)

| #  | ğŸ“„ Title                                                                   | ğŸ”— Link                                                                                                                  |
|----|----------------------------------------------------------------------------|--------------------------------------------------------------------------------------------------------------------------|
| 1  | Whatâ€™s Really Going On in Machine Learning? Some Minimal Models           | [Link](https://writings.stephenwolfram.com/2024/08/whats-really-going-on-in-machine-learning-some-minimal-models/)       |








## Computer vision

ğŸ”™ [Back to Categories](#quick-links)

| #  | ğŸ“„ Title                                                                 | ğŸ”— Link |
|----|--------------------------------------------------------------------------|--------|
| 1  |  Deep Learning for computer vision, by Andrej Karpathy    | [Link](https://youtube.com/playlist?list=PLkt2uSq6rBVctENoVBg1TpCC7OQi31AlC&si=9JudewH1OAUmhj1x) |
|2  | Computer Vision & Deep Learning (freeCodeCamp)  | [Link](https://youtu.be/IA3WxTTPXqQ) |
| 3 | Computer Vision with Prof. Tom Yeh    | [Link](https://youtube.com/playlist?list=PL0cq-CiC5QhutrhhsLLiybg2OehFOftI9&si=YXKiy5a_tdOWuR0z)|
| 4 |  Computer vision for dummies |[Link](https://www.visiondummy.com/)|
| 5 | Training CLIP Model from Scratch for an Fashion Image Retrieval App |[Link](https://learnopencv.com/clip-model/)|

 

## LLM Inference

ğŸ”™ [Back to Categories](#quick-links)

| #  | ğŸ“„ Title                                                                 | ğŸ”— Link |
|----|--------------------------------------------------------------------------|--------|
| 1  |  How to build an LLM inference engine using C++ and CUDA from scratch without libraries   | [Link](https://andrewkchan.dev/posts/yalm.html) |


## N8N

ğŸ”™ [Back to Categories](#quick-links)

| #  | ğŸ“„ Title                                                                 | ğŸ”— Link |
|----|--------------------------------------------------------------------------|--------|
| 1  |  The only video you need to Master N8N + AI agents (For complete beginners)   | [Link](https://www.youtube.com/watch?v=uScURRX-Knc) |


## AI Learning Guide
ğŸ”™ [Back to Categories](#quick-links)

| #  | ğŸ“„ Title                                                                 | ğŸ”— Link |
|----|--------------------------------------------------------------------------|--------|
| 1  | A survivor's guide to Artificial Intelligence courses at Stanford (Updated Feb 2020)| [Link](https://huyenchip.com/2018/03/30/guide-to-Artificial-Intelligence-Stanford.html) |






## Vision Transformer
ğŸ”™ [Back to Categories](#quick-links)

| #  | ğŸ“„ Title                                                                 | ğŸ”— Link |
|----|--------------------------------------------------------------------------|--------|
| 1  |  Vision Transformers Need Registers(2024)   | [Link](https://arxiv.org/abs/2309.16588) |



## Roadmap
ğŸ”™ [Back to Categories](#quick-links)

| #  | ğŸ“„ Title                                                                 | ğŸ”— Link |
|----|--------------------------------------------------------------------------|--------|
| 1  | MLOps guide  | [Link](https://huyenchip.com/mlops/) |



## Interview
ğŸ”™ [Back to Categories](#quick-links)

| #  | ğŸ“„ Title                                                                 | ğŸ”— Link |
|----|--------------------------------------------------------------------------|--------|
| 1  |Introduction to Machine Learning Interviews Book  | [Link](https://huyenchip.com/ml-interviews-book/) |








## AI beat Human

ğŸ”™ [Back to Categories](#quick-links)

| #  | ğŸ“„ Title                                                                 | ğŸ”— Link |
|----|--------------------------------------------------------------------------|--------|
| 1  |  O3 beats a master-level GeoGuessr player, even with fake EXIF data   | [Link](https://sampatt.com/blog/2025-04-28-can-o3-beat-a-geoguessr-master) |



## LLM Reasoning
ğŸ”™ [Back to Categories](#quick-links)

| #  | ğŸ“„ Title                                                                 | ğŸ”— Link |
|----|--------------------------------------------------------------------------|--------|
| 1  |  Understanding Reasoning LLMs by Sebastian Raschka   | [Link](https://www.linkedin.com/pulse/understanding-reasoning-llms-sebastian-raschka-phd-1tshc/) |


## Database

ğŸ”™ [Back to Categories](#quick-links)

| #  | ğŸ“„ Title                                                                 | ğŸ”— Link |
|----|--------------------------------------------------------------------------|--------|
| 1  |  Relational Databases vs Vector Databases  | [Link](https://zilliz.com/blog/relational-databases-vs-vector-databases) |








## Model Technical Paper

ğŸ”™ [Back to Categories](#quick-links)

| #  | ğŸ“„ Title                                                                 | ğŸ”— Link |
|----|--------------------------------------------------------------------------|--------|
| 1  |  DeepSeek-Prover-V2   | [Link](https://github.com/deepseek-ai/DeepSeek-Prover-V2/blob/main/DeepSeek_Prover_V2.pdf) |
| 2  | GPT-1 â†’ Improving Language Understanding by Generative Pre-Training(2018) |[Link](https://cdn.openai.com/research-covers/language-unsupervised/language_understanding_paper.pdf)|
| 3  | GPT-2 â†’ Language Models are Unsupervised Multitask Learners (2019) | [Link](https://cdn.openai.com/better-language-models/language_models_are_unsupervised_multitask_learners.pdf)|
| 4  | GPT-3 â†’ Language Models are Few-Shot Learners(2020) | [Link](https://arxiv.org/abs/2005.14165)|
| 5  | ChatGPT :Trained with RLHF â€“ Reinforcement Learning from Human Feedback (Ouyang et al., 2022) |[Link](https://arxiv.org/abs/2203.02155)|
| 6  |  GPT-4 â†’ GPT-4 Technical Report (2023) |[Link](https://cdn.openai.com/papers/gpt-4.pdf)|
| 7   | Claude (Anthropic) Constitutional AI: Harmlessness from AI Feedback (2022) | [Link](https://arxiv.org/pdf/2212.08073)|
| 8   | Gemini: A Family of Highly Capable Multimodal Models (2023) | [Link](https://arxiv.org/abs/2312.11805)|
| 9   | Start building with Gemini 2.5 Flash(2025) | [Link](https://developers.googleblog.com/en/start-building-with-gemini-25-flash/)|
| 10  | Gemma (Google) Gemma: Open Models for Responsible AI(2024)  | [Link](https://arxiv.org/abs/2403.08295)|
| 11|  Gemma 3 Technical Report(2025) | [Link](https://arxiv.org/abs/2503.19786)|
|12 | LLaMA Series (Meta AI) LLaMA: Open and Efficient Foundation Language Models(2023) |[Liink](https://arxiv.org/abs/2302.13971)|
| 13 |  LLaMA 2: Improved training and safety (2023) | [Link](https://arxiv.org/pdf/2307.09288)|
| 14 | Llama 3:The Llama 3 Herd of Models | [Link](https://arxiv.org/abs/2407.21783) |
| 15 | Llama 4:The beginning of a new era of natively multimodal AI innovation | [Link](https://ai.meta.com/blog/llama-4-multimodal-intelligence/)|
| 16 | Mistral AI(France) Mistral 7B: Grouped-query attention (2023) | [Link](https://arxiv.org/abs/2310.06825)|
| 17 | Kimi by Moonshot AI (China) Scaling RL with LLMs: Technical Report of Kimi k1.5 (2025) | [Link](https://arxiv.org/abs/2501.12599)|
| 18 | DeepSeek(China) DeepSeekMath: Pushing the Limits of Mathematical Reasoning in Open Language Models |[Link](https://arxiv.org/abs/2402.03300)|
| 19 |  DeepSeek-V3 Technical Report (2024) | [Link](https://arxiv.org/pdf/2412.19437)|
| 20 | DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning | [Link](https://arxiv.org/abs/2501.12948)| 
| 21 |  Qwen (China) Qwen Technical Report(2023)  | [Link](https://arxiv.org/pdf/2309.16609)|
| 22 | Qwen2 Technical Report(2024) | [Link](https://arxiv.org/pdf/2407.10671)|
| 23 |  Qwen2.5 Technical Report(2024) | [Link](https://arxiv.org/pdf/2412.15115)|
| 24 | Qwen2.5-Omni Technical Report Multimodel (2025) | [Link](https://arxiv.org/pdf/2503.20215) |
| 25 | Qwen3: Think Deeper, Act Faster (2025)          | [Link](https://qwenlm.github.io/blog/qwen3/)|
| 26 |  Phi-4-reasoning Technical Report (2025)        |[Link](https://arxiv.org/abs/2504.21318)|
| 27  | Phi-4-Mini-Reasoning: Exploring the Limits of Small Reasoning Language Models in Math (2025)|[Link](https://arxiv.org/pdf/2504.21233) |
| 28  | OpenAI's GPT-3 Language Model: A Technical Overview (2020) |[link](https://lambda.ai/blog/demystifying-gpt-3)|


OpenAI 


## LLM-powered phone

ğŸ”™ [Back to Categories](#quick-links)

| #  | ğŸ“„ Title                                                                 | ğŸ”— Link |
|----|--------------------------------------------------------------------------|--------|
| 1  | LLM-powered phone GUI agents in phone automation   | [Link](https://lnkd.in/ga3zuCu3) |






## Diffusion Model
ğŸ”™ [Back to Categories](#quick-links)

| #  | ğŸ“„ Title                                                                 | ğŸ”— Link |
|----|--------------------------------------------------------------------------|--------|
| 1  | Diffusion  Models from statistical first principles| [Link](https://lnkd.in/gUnVF4fe) |
| 2  | implement Diffusion Models from scratch w/ Transformer |[Link](https://lnkd.in/grszCbUr)|
| 3 |  Denoising Diffusion Probabilistic Models (Ho et al., 2020) |[Link]()|
| 4 | Playlist to learn Diffusion models |[Link](https://youtube.com/playlist?list=PLBoQnSflObcnYM35qBaDFQjaJEh_5Wx-O&si=3WT-F0q6hO2OpyNE)|



## NLP
ğŸ”™ [Back to Categories](#quick-links)

| #  | ğŸ“„ Title                                                                 | ğŸ”— Link |
|----|--------------------------------------------------------------------------|--------|
| 1  | ğ—Ÿğ—®ğ—»ğ—´ğ˜‚ğ—®ğ—´ğ—² ğ— ğ—¼ğ—±ğ—²ğ—¹ğ—¶ğ—»ğ—´ ğ—³ğ—¿ğ—¼ğ—º ğ—¦ğ—°ğ—¿ğ—®ğ˜ğ—°ğ—µ  Stanford University ğ—¡ğ—Ÿğ—£| [Link](https://lnkd.in/dShKKD2k) |
| 2  | NLP Demystified | [Link](https://www.nlpdemystified.org/course)|
|3  | 1.5 Stemming, Lemmatization, Stopwords, POS Tagging |[Link](https://www.nlplanet.org/course-practical-nlp/01-intro-to-nlp/05-tokenization-stemming-lemmatization.html)|
| 4 | A curated list of resources dedicated to Natural Language Processing (NLP) |[Link](https://github.com/keon/awesome-nlp)|
| 5 | Excited to teach Advanced NLP at CMU this semester |[Link](https://youtube.com/playlist?list=PLqC25OT8ZpD3WxQ0FwWMGPS_BcWdcKyZy&si=RltV5AyxIUJh-fdV)|






## Backpropagation
ğŸ”™ [Back to Categories](#quick-links)

| #  | ğŸ“„ Title                                                                 | ğŸ”— Link |
|----|--------------------------------------------------------------------------|--------|
| 1  | Learning Representations by Back-Propagating Errors (Rumelhart et al., 1986)| [Link](https://lnkd.in/gsN9XH3A) |



## Reward Modeling

ğŸ”™ [Back to Categories](#quick-links)

| #  | ğŸ“„ Title                                                                 | ğŸ”— Link |
|----|--------------------------------------------------------------------------|--------|
| 1  | Reward Modeling Part 1: Bradley-Terry Model | [Link](https://rlhflow.github.io/posts/2024-03-23-bradley-terry-reward-model/) |
| 2  | An interpretable reward modeling approach |[Link](https://rlhflow.github.io/posts/2024-05-29-multi-objective-reward-modeling/)|


## LLM preference

ğŸ”™ [Back to Categories](#quick-links)

| #  | ğŸ“„ Title                                                                 | ğŸ”— Link |
|----|--------------------------------------------------------------------------|--------|
| 1  | Interpreting Language Model Preferences Through the Lens of Decision Trees| [Link](https://rlhflow.github.io/posts/2025-01-22-decision-tree-reward-model/) |




## Positional Encoding


ğŸ”™ [Back to Categories](#quick-links)

| #  | ğŸ“„ Title                                                                 | ğŸ”— Link |
|----|--------------------------------------------------------------------------|--------|
| 1  | Linear Relationships in the Transformerâ€™s Positional Encoding| [Link](https://blog.timodenk.com/linear-relationships-in-the-transformers-positional-encoding/) |
| 2  | Transformer Architecture: The Positional Encoding |[Link](https://kazemnejad.com/blog/transformer_architecture_positional_encoding/)|








## Attention
ğŸ”™ [Back to Categories](#quick-links)

| #  | ğŸ“„ Title                                                                 | ğŸ”— Link |
|----|--------------------------------------------------------------------------|--------|
| 1  | Attention Is All You Need (Vaswani et al., 2017) | [Link](https://lnkd.in/gXUccydp) |
| 2  | Implement Flash Attention Backend in SGLang - Basics and KV Cache(2025) |[Link](https://hebiao064.github.io/fa3-attn-backend-basic)|
| 3  | Visualizing A Neural Machine Translation Model (Mechanics of Seq2seq Models With Attention) |[Link](https://jalammar.github.io/visualizing-neural-machine-translation-mechanics-of-seq2seq-models-with-attention/)|






## BERT

ğŸ”™ [Back to Categories](#quick-links)

| #  | ğŸ“„ Title                                                                 | ğŸ”— Link |
|----|--------------------------------------------------------------------------|--------|
| 1  | BERT: Pre-training of Deep Bidirectional Transformers (Devlin et al., 2018) | [Link](https://lnkd.in/gGjmS5aD) |



## Chunking

ğŸ”™ [Back to Categories](#quick-links)

| #  | ğŸ“„ Title                                                                 | ğŸ”— Link |
|----|--------------------------------------------------------------------------|--------|
| 1  | Chunking Strategies for LLM Applications(2023) | [Link](https://www.pinecone.io/learn/chunking-strategies/#Chunking-methods) |



## LLM alignment
ğŸ”™ [Back to Categories](#quick-links)

| #  | ğŸ“„ Title                                                                 | ğŸ”— Link |
|----|--------------------------------------------------------------------------|--------|
| 1  | Alignment Guidebook | [Link](https://rlhflow.github.io/posts/2024-03-26-alignment-guidebook/) |






## Few-Shot 

ğŸ”™ [Back to Categories](#quick-links)

| #  | ğŸ“„ Title                                                                 | ğŸ”— Link |
|----|--------------------------------------------------------------------------|--------|
| 1  | Language Models are Few-Shot Learners (Brown et al., 2020) | [Link](https://lnkd.in/gGPzgTX8) |


## Chain of Thought

ğŸ”™ [Back to Categories](#quick-links)

| #  | ğŸ“„ Title                                                                 | ğŸ”— Link |
|----|--------------------------------------------------------------------------|--------|
| 1  | Chain of Thought Prompting (Wei et al., 2022)| [Link](https://lnkd.in/gAaQkzF3) |

## Scaling Laws

ğŸ”™ [Back to Categories](#quick-links)

| #  | ğŸ“„ Title                                                                 | ğŸ”— Link |
|----|--------------------------------------------------------------------------|--------|
| 1  | Scaling Laws for Neural Language Models (Kaplan et al., 2020)| [Link](https://lnkd.in/g8Y7x68h) |




## AGI

ğŸ”™ [Back to Categories](#quick-links)

| #  | ğŸ“„ Title                                                                 | ğŸ”— Link |
|----|--------------------------------------------------------------------------|--------|
| 1  | AGI is not a milestone | [Link](https://www.aisnakeoil.com/p/agi-is-not-a-milestone) |



## History

ğŸ”™ [Back to Categories](#quick-links)

| #  | ğŸ“„ Title                                                                 | ğŸ”— Link |
|----|--------------------------------------------------------------------------|--------|
| 1  | When ChatGPT Broke an Entire Field: An Oral History(2025) | [Link](https://www.quantamagazine.org/when-chatgpt-broke-an-entire-field-an-oral-history-20250430/) |
| 2  | From Large Language Models to Reasoning Language Models - Three Eras in The Age of Computation. |[Link](https://youtu.be/NFwZi94S8qc?si=_ucrz4YEvr4_fPzN)|



## DPO

ğŸ”™ [Back to Categories](#quick-links)

| #  | ğŸ“„ Title                                                                 | ğŸ”— Link |
|----|--------------------------------------------------------------------------|--------|
| 1  |  Direct Preference Optimization (Rafailov et al., 2023)| [Link](https://lnkd.in/gzmknGCQ) |

## LoRA

ğŸ”™ [Back to Categories](#quick-links)

| #  | ğŸ“„ Title                                                                 | ğŸ”— Link |
|----|--------------------------------------------------------------------------|--------|
| 1  |  LoRA: Low-Rank Adaptation (Hu et al., 2021) | [Link](https://lnkd.in/gK4W7YUh) |

## Topic Comparison

ğŸ”™ [Back to Categories](#quick-links)

| #  | ğŸ“„ Title                                                                 | ğŸ”— Link |
|----|--------------------------------------------------------------------------|--------|
| 1  |  Fine-Tuning vs Retrieval Augmented Generation(2023) | [Link](https://www.vectara.com/blog/fine-tuning-vs-retrieval-augmented-generation) |
| 2  |


## RAG

ğŸ”™ [Back to Categories](#quick-links)

| #  | ğŸ“„ Title                                                                 | ğŸ”— Link |
|----|--------------------------------------------------------------------------|--------|
| 1  |  Retrieval-Augmented Generation (Lewis et al., 2020) | [Link](https://lnkd.in/gp7y4zFu) |
| 2  | Advanced RAG: Precise Zero-Shot Dense Retrieval with HyDE |[Link](https://blog.lancedb.com/advanced-rag-precise-zero-shot-dense-retrieval-with-hyde-0946c54dfdcb/)|
| 3  | Retrieval Augmented Generation (RAG) from Scratch â€” Tutorial For Dummies | [Link](https://zacharyhuang.substack.com/p/retrieval-augmented-generation-rag)|
|  4 | Multi-modal RAG |[Link](https://github.com/langchain-ai/langchain/blob/master/cookbook/Multi_modal_RAG.ipynb?ref=blog.langchain.dev)|
| 5  |  Beginner's Guide to RAG by Tom Yeh |[Link](https://www.youtube.com/watch?v=PrYuqtT43BE) |
| 6  | Retrieval Augmented Generation ,Ragas|[Link](https://docs.ragas.io/en/latest/concepts/metrics/available_metrics/)|
| 7 | Simplest Method to improve RAG pipeline: Re-Ranking (2023)|[link](https://blog.lancedb.com/simplest-method-to-improve-rag-pipeline-re-ranking-cf6eaec6d544/)|


## RLHF

ğŸ”™ [Back to Categories](#quick-links)

| #  | ğŸ“„ Title                                                                 | ğŸ”— Link |
|----|--------------------------------------------------------------------------|--------|
| 1  |  Reinforcement Learning from Human Feedback by Nathan Lambert | [Link](https://rlhfbook.com/) |
| 2  | RLHF: Reinforcement Learning from Human Feedback by Chip Huyen |[Link](https://huyenchip.com/2023/05/02/rlhf.html) |





## Reinforcement Learning

ğŸ”™ [Back to Categories](#quick-links)

| #  | ğŸ“„ Title                                                                 | ğŸ”— Link |
|----|--------------------------------------------------------------------------|--------|
| 1  |  Berkeley CS 294: Deep Reinforcement Learning | [Link](https://lnkd.in/gxYEcpJ9) |
| 2  | Spinning Up in Deep Reinforcement Learning - A free deep reinforcement learning course by OpenAI (2019) |[Link](https://lnkd.in/gd7kgQUZ)|
| 3  |  comprehensive overview of Reinforcement Learning methods |[Link](https://arxiv.org/abs/2412.05265)|

## AI Youtube Channel
ğŸ”™ [Back to Categories](#quick-links)

| #  | ğŸ“„ Title                                                                 | ğŸ”— Link |
|----|--------------------------------------------------------------------------|--------|
| 1  |  ğ—§ğ˜„ğ—¼ ğ— ğ—¶ğ—»ğ˜‚ğ˜ğ—² ğ—£ğ—®ğ—½ğ—²ğ—¿ğ˜€ | [Link](https://lnkd.in/d2MWB7a9) |
| 2  | ğ——ğ—²ğ—²ğ—½ğ—Ÿğ—²ğ—®ğ—¿ğ—»ğ—¶ğ—»ğ—´ ğ—”ğ—œ |[Link](https://lnkd.in/dKxtcCCU)|
| 3  | ğ—Ÿğ—²ğ˜… ğ—™ğ—¿ğ—¶ğ—±ğ—ºğ—®ğ—»     | [Link](https://lnkd.in/dyZe9v8m) |
| 4  | 3ğ—•ğ—¹ğ˜‚ğ—²1ğ—•ğ—¿ğ—¼ğ˜„ğ—»     |[Link](https://lnkd.in/dfEuTf_r) |
|  5  | ğ—”ğ—»ğ—±ğ—¿ğ—²ğ—· ğ—ğ—®ğ—¿ğ—½ğ—®ğ˜ğ—µğ˜† |[Link](https://lnkd.in/dFjV3j4d)|
| 6   | ğ—¦ğ—²ğ—»ğ˜ğ—±ğ—²ğ˜…         |[Link](https://lnkd.in/dXX3xCTE)|
|7    | ğ— ğ—®ğ˜ğ˜ ğ—ªğ—¼ğ—¹ğ—³ğ—²     | [Link](https://lnkd.in/d798mz9h) |

## AI Blog
ğŸ”™ [Back to Categories](#quick-links)

| #  | ğŸ“„ Title                                                                 | ğŸ”— Link |
|----|--------------------------------------------------------------------------|--------|
| 1  |  ğ—§ğ—¼ğ˜„ğ—®ğ—¿ğ—±ğ˜€ğ——ğ—®ğ˜ğ—®ğ—¦ğ—°ğ—¶ğ—²ğ—»ğ—°ğ—² | [Link](https://lnkd.in/dyasxKUU) |
| 2  | ğ—¢ğ—½ğ—²ğ—»ğ—”ğ—œ ğ—•ğ—¹ğ—¼ğ—´|[Link](https://openai.com/news/)|
| 3  | ğ— ğ—®ğ—¿ğ—¸ğ—§ğ—²ğ—°ğ—µğ—£ğ—¼ğ˜€ğ˜     | [Link](https://lnkd.in/dxb3yCJs) |
| 4  | ğ——ğ—²ğ—²ğ—½ğ— ğ—¶ğ—»ğ—± ğ—•ğ—¹ğ—¼ğ—´   |[Link](https://lnkd.in/du9i_m3x) |
|  5  | ğ—”ğ—»ğ˜ğ—µğ—¿ğ—¼ğ—½ğ—¶ğ—° ğ—•ğ—¹ğ—¼ğ—´|[Link](https://lnkd.in/dS-P3ktx)|
| 6   | ğ—•ğ—²ğ—¿ğ—¸ğ—²ğ—¹ğ—²ğ˜† ğ—•ğ—®ğ—¶ğ—¿      |[Link](https://bair.berkeley.edu/)|
|7    | ğ—›ğ˜‚ğ—´ğ—´ğ—¶ğ—»ğ—´ğ—³ğ—®ğ—°ğ—² ğ—•ğ—¹ğ—¼ğ—´   | [Link](https://lnkd.in/dTqzeHJ4) |
| 8    | google Research   |[Link](https://research.google/)|
| 9  |  Mehmet Burak SayÄ±cÄ± |[Link](https://mburaksayici.com/blog/)|

## Embedding
ğŸ”™ [Back to Categories](#quick-links)

| #  | ğŸ“„ Title                                                                 | ğŸ”— Link |
|----|--------------------------------------------------------------------------|--------|
| 1  |  LLM Embedding Explained | [Link](https://lnkd.in/gAJY3XxX) |



## AI Math
ğŸ”™ [Back to Categories](#quick-links)

| #  | ğŸ“„ Title                                                                 | ğŸ”— Link |
|----|--------------------------------------------------------------------------|--------|
| 1  |  Matrix Calulus for Machine Learning and Beyond  | [Link](https://ocw.mit.edu/courses/18-s096-matrix-calculus-for-machine-learning-and-beyond-january-iap-2023/pages/lecture-notes/) |
| 2 | history of mathematics | [Link](https://www.math.uci.edu/~ndonalds/)|

## Neural Network
ğŸ”™ [Back to Categories](#quick-links)

| #  | ğŸ“„ Title                                                                 | ğŸ”— Link |
|----|--------------------------------------------------------------------------|--------|
| 1  |  LLMs work by 3b1b | [Link](https://youtu.be/aircAruvnKk?si=tCDwjCWULpURXbBN) |




## Books
ğŸ”™ [Back to Categories](#quick-links)

| #  | ğŸ“„ Title                                                                 | ğŸ”— Link |
|----|--------------------------------------------------------------------------|--------|
| 1  |  Python Crash course  | [Link](https://github.com/bhoop70233/AI-Books/blob/main/2nd.Python-Crash-Course-1.pdf) |
| 2  | Cloud Data Science for Dummies |[Link](https://github.com/bhoop70233/AI-Books/blob/main/Cloud-Data-Science-for-Dummies.pdf)|
| 3  | Cost-Effective Data Pipelines |[Link](https://github.com/bhoop70233/AI-Books/blob/main/Cost-Effective%20Data%20Pipelin_%20(Z-Library).pdf)|
|  4 | DATA ENGINEER With Python | [Link](https://github.com/bhoop70233/AI-Books/blob/main/DATA%20ENGINEER.pdf)|
|  5 | Data Pipelines Pocket Reference |[Link](https://github.com/bhoop70233/AI-Books/blob/main/Data%20Pipelines%20Pocket%20Refer_%20(Z-Library).pdf)|
|   6 | Data Internals A Deep Dive into How Distributed data systems work|[Link](https://github.com/bhoop70233/AI-Books/blob/main/Database%20Internals%20A%20Deep%20D_%20(Z-Library).pdf)|
|  7 | Deciphering Data Architectures |[Link](https://github.com/bhoop70233/AI-Books/blob/main/Deciphering%20Data%20Architectu_%20(Z-Library).pdf)|
|  8 | Foundations of Scalable systems |[Link](https://github.com/bhoop70233/AI-Books/blob/main/Foundations%20of%20Scalable%20Sys_%20(Z-Library).pdf)|
|  9 | Fundamentals of Data Engineering_ Plan and Build Robust Data Systems |[Link](https://github.com/bhoop70233/AI-Books/blob/main/Fundamentals%20of%20Data%20Engineering_%20Plan%20and%20Build%20Robust%20Data%20Systems%20by%20Joe%20Reis.pdf)|
| 10  | Hadoop The Definitive Guide |[Link](https://github.com/bhoop70233/AI-Books/blob/main/Hadoop%20The%20Definitive%20Guide_%20(Z-Library).pdf)|
|  11 | Introduction to Machine Learning with Python |[Link](https://github.com/bhoop70233/AI-Books/blob/main/Introduction%20to%20Machine%20Learning%20with%20Python%20(%20PDFDrive.com%20)-min.pdf)|
|  12 |  SQL for Data Analysis |[Link](https://github.com/bhoop70233/AI-Books/blob/main/SQL%20for%20Data%20Analysis.pdf)|
|  13 |Storytelling with Data_ A Data Visualization Guide for Business Professionals |[Link](https://github.com/bhoop70233/AI-Books/blob/main/Storytelling%20with%20Data_%20A%20Data%20Visualization%20Guide%20for%20Business%20Professionals%20(%20PDFDrive%20).pdf)|
| 14 | Terraform Up and Running |[Link](https://github.com/bhoop70233/AI-Books/blob/main/Terraform%20%20Up%20and%20Running%20(Early%20Release)%20(%20PDFDrive%20).pdf)|
| 15 |The Data Engineer Skills & Tools Guide | [Link](https://github.com/bhoop70233/AI-Books/blob/main/The%20Data%20Engineer%20Skills%20%26%20Tools%20Guide.pdf)|
|16  |The Data Warehouse Toolkit  |[Link](https://github.com/bhoop70233/AI-Books/blob/main/The%20Data%20Warehouse%20Toolkit%2C_%20(Z-Library).pdf)|
| 17 | Think Stats, 2nd Edition_ Exploratory Data Analysis | [Link](https://github.com/bhoop70233/AI-Books/blob/main/Think%20Stats%2C%202nd%20Edition_%20Exploratory%20Data%20Analysis%20(%20PDFDrive%20).pdf)|
|18 | kafka  the definitive guide|[Link](https://github.com/bhoop70233/AI-Books/blob/main/kafka_%20the%20definitive%20guide.pdf)|
| 19 |practical synthetic data generation balancing privacy and the broad availability of data | [Link](https://github.com/bhoop70233/AI-Books/blob/main/practical-synthetic-data-generation-balancing-privacy-and-the-broad-availability-of-data-9781492072690-1492072699.pdf)|
| 20 | Understanding Deep Learning |[Link](https://udlbook.github.io/udlbook/)|
| 21 | Dive into Deep Learning   | [Link](https://d2l.ai/)|


## LLM Reinforcement Learning

ğŸ”™ [Back to Categories](#quick-links)

| #  | ğŸ“„ Title                                                                 | ğŸ”— Link |
|----|--------------------------------------------------------------------------|--------|
| 1  |  Asynchronous Deep Reinforcement Learning (Google Deepmind 2016) | [Link](https://arxiv.org/pdf/1602.01783) |
| 2  | Reinforcement Learning from Human (OpenAI 2017)|[Link](https://arxiv.org/pdf/1706.03741)|
| 3  | Proximal Policy Optimization (OpenAI 2017)   | [Link](https://arxiv.org/pdf/1707.06347) |
| 4  |Fine-Tuning Language Models from Human Preferences (OpenAI 2020) |[Link](https://arxiv.org/pdf/1909.08593) |
|  5  | Learning to Summarize from Human Feedback (OpenAI 2022)|[Link](https://arxiv.org/pdf/2009.01325)|
| 6   | Direct Preference Optimization( Stanford University 2023)|[Link](https://arxiv.org/pdf/2305.18290)|
|7    | Group Relative Policy Optimization ( DeepSeek 2024) | [Link](https://arxiv.org/pdf/2402.03300) |
| 8   |  Reinforcement learning with verifiable rewards (DeepSeek 2025) | [Link](https://arxiv.org/pdf/2412.19437v1)|
| 9   |  Reinforcement Learning from Human Feedback (Nathan Lambert)   | [Link](https://rlhfbook.com/c/11-policy-gradients.html)|


## Mixture of expert

ğŸ”™ [Back to Categories](#quick-links)

| #  | ğŸ“„ Title                                                                 | ğŸ”— Link |
|----|--------------------------------------------------------------------------|--------|
| 1  |  OUTRAGEOUSLY LARGE NEURAL NETWORKS: THE SPARSELY-GATED MIXTURE-OF-EXPERTS LAYER| [Link](https://arxiv.org/pdf/1701.06538) |


## UC Berkeley University


ğŸ”™ [Back to Categories](#quick-links)

| #  | ğŸ“„ Title                                                                 | ğŸ”— Link |
|----|--------------------------------------------------------------------------|--------|
| 1  |  Large Language Model Agents ,(Fall 2024)| [Link](https://llmagents-learning.org/f24) |
| 2  |  Advanced Large Language Model Agents(spring 2025) |[Link](https://llmagents-learning.org/sp25)|
| 3  | CS 294-131: Special Topics in Deep Learning Fall, 2016 |[Link](https://berkeley-deep-learning.github.io/cs294-dl-f16/)|
| 4  |CS 294-131: Special Topics in Deep Learning Spring 2017 |[Link](https://berkeley-deep-learning.github.io/cs294-131-s17/)|
| 5 | CS 294-131: Special Topics in Deep Learning Fall 2017 |[Link](https://berkeley-deep-learning.github.io/cs294-131-f17/)|
|6 | CS 294-131: Special Topics in Deep Learning Spring 2018 |[Link](https://berkeley-deep-learning.github.io/cs294-131-s18/)|
|  7 | CS 294-131: Trustworthy Deep Learning (Special Topics in Deep Learning) Spring 2019| [Link](https://berkeley-deep-learning.github.io/cs294-131-s19/)|
|  8 | CS294/194-196: Responsible GenAI and Decentralized Intelligence Fall 2023 |[Link](https://rdi.berkeley.edu/responsible-genai/f23)|
| 9 | CS294-267/CS194-267 Understanding Large Language Models: Foundations and Safety Spring 24|[Link](https://rdi.berkeley.edu/understanding_llms/s24)|





## Fine-tuning

ğŸ”™ [Back to Categories](#quick-links)

| #  | ğŸ“„ Title                                                                 | ğŸ”— Link |
|----|--------------------------------------------------------------------------|--------|
| 1  | finetune Phi-4 for free on Colab| [Link](https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Phi_4-Conversational.ipynb) |
| 2 | Understanding Parameter-Efficient Finetuning of Large Language Models: From Prefix Tuning to LLaMA-Adapters | [Link](https://sebastianraschka.com/blog/2023/llm-finetuning-llama-adapter.html)|
| 3 | Practical Tips for Finetuning LLMs Using LoRA (Low-Rank Adaptation) |[Link](https://magazine.sebastianraschka.com/p/practical-tips-for-finetuning-llms)|
| 4 | PEFT: Parameter-Efficient Fine-Tuning of Billion-Scale Models on Low-Resource Hardware|[Link](https://huggingface.co/blog/peft)|



## Tensor

ğŸ”™ [Back to Categories](#quick-links)

| #  | ğŸ“„ Title                                                                 | ğŸ”— Link |
|----|--------------------------------------------------------------------------|--------|
| 1  | Tensor Product Attention Is All You Need| [Link](https://tensorgi.github.io/T6/) |








## Supervised Learning

ğŸ”™ [Back to Categories](#quick-links)

| #  | ğŸ“„ Title                                                                 | ğŸ”— Link |
|----|--------------------------------------------------------------------------|--------|
| 1  | Supervised Learning: A Comprehensive Guide| [Link](https://medium.com/@kodeinkgp/supervised-learning-a-comprehensive-guide-7032b34d5097) |



## IISC Bangalore


ğŸ”™ [Back to Categories](#quick-links)

| #  | ğŸ“„ Title                                                                 | ğŸ”— Link |
|----|--------------------------------------------------------------------------|--------|
| 1  |  started with AI from Basics to Advance as were taught to me at IISC Bangalore as part of Mtech AI | [Link](https://linktr.ee/Victor_explore) |




## AI Agent

ğŸ”™ [Back to Categories](#quick-links)

| #  | ğŸ“„ Title                                                                 | ğŸ”— Link |
|----|--------------------------------------------------------------------------|--------|
| 1  | Hugging Face Agents Course | [Link](https://github.com/huggingface/agents-course) |
| 2   | Agents  by Chip Huyen             |[Link](https://huyenchip.com/2025/01/07/agents.html)|
| 3  |  Large Language Model Agents MOOC, Fall 2024|[Link](https://llmagents-learning.org/f24)|
| 4  | Advanced Large Language Model Agents MOOC, Spring 2025 |[Link](https://llmagents-learning.org/sp25)|




## Artificial Intelligence

ğŸ”™ [Back to Categories](#quick-links)

| #  | ğŸ“„ Title                                                                 | ğŸ”— Link |
|----|--------------------------------------------------------------------------|--------|
| 1  | lgorithms for AI & ML | [Link](https://web.stanford.edu/~mossr/pdf/alg4ai.pdf) |




## Prompt Engineering

ğŸ”™ [Back to Categories](#quick-links)

| #  | ğŸ“„ Title                                                                 | ğŸ”— Link |
|----|--------------------------------------------------------------------------|--------|
| 1  | prompt engineering white paper | [Link](https://www.kaggle.com/whitepaper-prompt-engineering) |




## Statistical
ğŸ”™ [Back to Categories](#quick-links)

| #  | ğŸ“„ Title                                                                 | ğŸ”— Link |
|----|--------------------------------------------------------------------------|--------|
| 1  | Practical Statistics for data scientists | [Link](http://103.203.175.90:81/fdScript/RootOfEBooks/E%20Book%20collection%20-%202023%20-%20E/CSE%20ITAIDSML/Practical_Statistics_for_Data_Scientist_by_Peter_Bruce,_Andrew_Bruce.pdf) |
| 2  | The Elements of Statistical Learning |[Link](https://www.sas.upenn.edu/~fdiebold/NoHesitations/BookAdvanced.pdf)|
| 3   | Naked Statistics: stripping the dread from the data | [Link](https://pdfroom.com/books/naked-statistics-stripping-the-dread-from-the-data/or5WWyBP5qD) |
|4   | How to Lie with Statistics |[Link](https://mronline.org/wp-content/uploads/2019/05/HowToLieWithStatistics.pdf)|
| 5 | All of Statistics | [Link](https://lin-yu.me/books/all_of_statistics.pdf)|



## Generative AI

ğŸ”™ [Back to Categories](#quick-links)

| #  | ğŸ“„ Title                                                                 | ğŸ”— Link |
|----|--------------------------------------------------------------------------|--------|
| 1  | Microsoft launched the best course on Generative AI | [Link](https://microsoft.github.io/generative-ai-for-beginners/#/) |



## Stanford University


ğŸ”™ [Back to Categories](#quick-links)

| #  | ğŸ“„ Title                                                                 | ğŸ”— Link |
|----|--------------------------------------------------------------------------|--------|
| 1  |  STATS 202: Data Mining and Analysis | [Link](http://web.stanford.edu/class/stats202/intro.html) |
| 2  |  CS109: Introduction to Probability for Computer Scientists |[Link](http://web.stanford.edu/class/archive/cs/cs109/cs109.1166/) |
| 3 | CS231N: Convolutional Neural Networks for Visual Recognition |[Link](https://cs231n.stanford.edu/) |
| 4 | CS224N: Natural Language Processing with Deep Learning |[Link](https://web.stanford.edu/class/cs224n/)|
| 5 | CS229: Machine Learning |[Link](https://cs229.stanford.edu/)|
| 6  | CS221: Artificial Intelligence: Principles and Techniques |[Link](https://stanford-cs221.github.io/spring2025/)|
| 7  | CS228: Probabilistic Graphical Models: Principles and Techniques |[Link](https://ermongroup.github.io/cs228-notes/)|
| 8  | CS234: Reinforcement Learning | [Link](https://web.stanford.edu/class/cs234/index.html)|
| 9  | CS238: Decision Making under Uncertainty (AA 228)  | [Link](https://aa228.stanford.edu/)|
| 10 | CS224W: Machine Learning with Graphs  | [Link](https://web.stanford.edu/class/cs224w/)|
| 11 | CS246: Mining Massive Data Sets | [Link](https://web.stanford.edu/class/cs246/) |
| 12 | CS230: Deep Learning   | [Link](https://cs230.stanford.edu/)|
| 13 | CS236: Deep Generative Models  | [Link](https://deepgenerativemodels.github.io/)
| 14 | EE263: Introduction to Linear Dynamical Systems | [Link](https://ee263.stanford.edu/) |
| 15 | CS336: Robot Perception and Decision-Making  | [Link](https://stanford-cs336.github.io/spring2025/) |


## Top AI Papers of the Week

ğŸ”™ [Back to Categories](#quick-links)

| #  | ğŸ“„ Title                                                                 | Week            |
|----|--------------------------------------------------------------------------|-----------------|
| 1  | 1. [Phi-4-Mini-Reasoning ](https://arxiv.org/abs/2504.21233)   2. [ Building Production-Ready AI Agents with Scalable Long-Term Memory](https://arxiv.org/abs/2504.19413) 3. [UniversalRAG](https://arxiv.org/abs/2504.20734) 4.[DeepSeek-Prover-V2](https://arxiv.org/abs/2504.21801) 5. [Kimi-Audio](https://github.com/MoonshotAI/Kimi-Audio/blob/master/assets/kimia_report.pdf) 6. [MiMo-7B](https://github.com/XiaomiMiMo/MiMo/blob/main/MiMo-7B-Technical-Report.pdf) 7.[Advances and Challenges in Foundation Agents](https://www.linkedin.com/pulse/top-ai-papers-week-dair-ai-tcbfe/) 8.[MAGI](https://arxiv.org/abs/2504.18260) 9.[A Survey of Efficient LLM Inference Serving](https://arxiv.org/abs/2504.19720) 10. [LLM for Engineering](https://arxiv.org/abs/2504.19394)|(April 28 - May 4,2025)|
























































 








